%
%  $Author: ienne $
%  $Date: 1995/09/15 15:20:59 $
%  $Revision: 1.4 $
%

% \documentclass[10pt,journal,cspaper,compsoc]{IEEEtran}   %%%tc version
\documentclass[10pt, conference]{IEEEtran}
%\documentclass[conference,compsoc]{IEEEtran}
%\documentclass[10pt, conference]{IEEEtran}
%\documentclass[times, 10pt,onecolumn]{article}
\usepackage{amsmath, amssymb, enumerate}

%%%%%%%%%%%%%%%% page control%%%%%%%%%%%%%%%%%
%\usepackage[margin=0.75in]{geometry}

%\linespread{0.991}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% this is really useful
%\usepackage{cite}
\usepackage{fancybox}
\usepackage{amsfonts}
%\usepackage{algorithm}
%\usepackage[noend]{algorithmic}
\usepackage[usenames]{color}
%\usepackage{colortbl}
%\usepackage[ figure, boxed, vlined]{algorithm2e}
%\usepackage[linesnumbered,vlined]{algorithm2e}
%\usepackage[lined,boxed]{algorithm2e}
\usepackage{listings}

\usepackage[linesnumbered,vlined]{algorithm2e}
\usepackage{graphicx}
\usepackage{times}
\usepackage{psfrag}
\usepackage{subfigure}
\usepackage{caption}
%\usepackage{subcaption}
\usepackage{multirow}
%\usepackage{setspace}
%\usepackage{listings}
\usepackage{epsfig}
%\usepackage{epstopdf}
%\usepackage[font=small,labelfont=bf]{caption}
\usepackage{url}

\usepackage{color}
\def\fixme#1{\typeout{FIXED in page \thepage : {#1}}
%\bgroup \color{red}{} \egroup}
\bgroup \color{red}{[FIXME: {#1}]} \egroup}


\usepackage[pdftex]{hyperref}
\usepackage{rotating,tabularx}

\interfootnotelinepenalty=10000

%% Define a new 'leo' style for the package that will use a smaller font.
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\small\ttfamily}}}
\makeatother

%\documentstyle[times,art10,twocolumn,latex8]{article}

%-------------------------------------------------------------------------
% take the % away on next line to produce the final camera-ready version
\pagestyle{plain}
%\thispagestyle{empty}
%\pagestyle{empty}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}

%% remaining budget share, used in task stall section.
\newcommand{\bottomrule}{\hline}
\newcommand{\toprule}{\hline}
\newcommand{\midrule}{\hline}
%-------------------------------------------------------------------------
\begin{document}

\title{DeepPicar:​ ​A​ ​Low-cost​ ​Deep​ ​Neural​ ​Network-based​ ​Autonomous​ ​Car}
\author{Michael Garrett Bechtel, Elise McEllhiney, Heechul Yun\\
\{m783b224, e908m429, heechul.yun\}@ku.edu\\
University of Kansas, USA\\ 
}

\maketitle
\thispagestyle{empty}
\begin{abstract}
We present DeepPicar, a low-cost deep neural network (DNN) based
autonomous car platform. DeepPicar is a small scale
replication of a real self-driving car called Dave-2 by NVIDIA, which
drove on public roads using a deep convolutional neural network (CNN), 
that takes images from a front-facing camera as input and produces
car steering angles as output. DeepPicar uses the exact same network
architecture---9 layers, 27 million connections and 24K
parameters---and can be trained to drive itself, in real-time, using a
web camera and a modest Raspberry Pi 3 quad-core platform.
Using DeepPicar, we analyze Pi 3's computing capabilities to 
support end-to-end deep learning based real-time control of autonomous
vehicles. We also systematically compare other contemporary embedded
computing platforms using the DeepPicar's CNN based real-time control
software as a workload. 
We find all tested platforms, including the Pi 3, are capable of
supporting deep-learning based real-time control, from 20 Hz up to 100
Hz depending on hardware platform. 
However, shared resource contention remains an
important issue that must be considered in applying deep-learning
models on shared memory based embedded computing platforms.

%% In order to effectively research autonomous vehicles, a real-time
%% capable platform is required. Such platforms can be hard to obtain, or
%% build, as the necessary components can be expensive. In this paper,
%% we present a low-cost alternative platform that utilizes a Raspberry
%% Pi 3 Model B, along with a single external camera sensor, to perform
%% all necessary self-driving operations. A convolutional neural network
%% (CNN) is employed and trained with input from a human driver to
%% navigate a custom made track. We display the real-time efficacy of our
%% platform in experiments with varying amounts of computational resources
%% and/or intensive AI workloads. To gain a better understanding of our
%% platform's potential, we compare it to other embedded computing
%% platforms to determine which are suitable for autonomous driving
%% research.
\end{abstract}

%-------------------------------------------------------------------------
\input{intro}
\input{background}
\input{overview}
\input{evaluation}
\input{comparison}
% \input{related}
\input{conclusion}
%-------------------------------------------------------------------------
\bibliographystyle{abbrv}
\bibliography{reference}

\appendix
\input{appendix}
\end{document}
