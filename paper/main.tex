\documentclass[a4paper,UKenglish]{lipics-v2016}
%This is a template for producing LIPIcs articles. 
%See lipics-manual.pdf for further information.
%for A4 paper format use option "a4paper", for US-letter use option "letterpaper"
%for british hyphenation rules use option "UKenglish", for american hyphenation rules use option "USenglish"
% for section-numbered lemmas etc., use "numberwithinsect"
 
\usepackage{microtype}%if unwanted, comment out or use option "draft"
\usepackage{adjustbox}
\usepackage{color}
\def\fixme#1{\typeout{FIXED in page \thepage : {#1}}
%  \bgroup \color{red}{} \egroup}
\bgroup \color{red}{[FIXME: {#1}]} \egroup}

%\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory

\bibliographystyle{plainurl}% the recommended bibstyle

% Author macros::begin %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{DeepPicar: A Low-cost Deep Neural Network-based Autonomous Car}
\titlerunning{DeepPicar: A Low-cost Autonomous Car}
%optional, in case that the title is too long; the running title should fit into the top page column

%% Please provide for each author the \author and \affil macro, even when authors have the same affiliation, i.e. for each author there needs to be the  \author and \affil macros
\author[1]{Michael G. Bechtel}
\author[2]{Elise McEllhiney}
\author[3]{Minje Kim}
\author[4]{Heechul Yun}
\affil[1]{University of Kansas, Lawrence, United States\\
  \texttt{mbechtel@ku.edu}}
\affil[2]{University of Kansas, Lawrence, United States\\
  \texttt{e908m429@ku.edu}}
\affil[3]{Indiana University, Bloomington, United States\\
  \texttt{e908m429@ku.edu}}
\affil[4]{University of Kansas, Lawrence, United States\\
  \texttt{heechul.yun@ku.edu}}
\authorrunning{M.\,G. Bechtel, E. McEllhiney, H. Yun} %mandatory. First: Use abbreviated first/middle names. Second (only in severe cases): Use first author plus 'et. al.'

\Copyright{Michael G. Bechtel, Elise McEllhiney, Heechul Yun}%mandatory, please use full first names. LIPIcs license is "CC-BY";  http://creativecommons.org/licenses/by/3.0/

\subjclass{C.4 PERFORMANCE OF SYSTEMS}% mandatory: Please choose ACM 1998 classifications from http://www.acm.org/about/class/ccs98-html . E.g., cite as "F.1.1 Models of Computation". 
\keywords{Real-time, Autonomous car, Convolutional neural network, Case study}% mandatory: Please provide 1-5 keywords
% Author macros::end %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{Sebastian Altmeyer}
\EventNoEds{1}
\EventLongTitle{30th Euromicro Conference on Real-Time Systems (ECRTS 2018)}
\EventShortTitle{ECRTS 2018}
\EventAcronym{ECRTS}
\EventYear{2018}
\EventDate{July 3--6, 2018}
\EventLocation{Barcelona, Spain}
\EventLogo{}
\SeriesVolume{XX}
\ArticleNo{YY}
% Editor-only macros::end %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\maketitle
\thispagestyle{empty}
\begin{abstract}
We present DeepPicar, a low-cost deep neural network (DNN) based
autonomous car platform. DeepPicar is a small scale
replication of a real self-driving car called Dave-2 by NVIDIA, which
drove on public roads using a deep convolutional neural network (CNN), 
that takes images from a front-facing camera as input and produces
car steering angles as output. DeepPicar uses the exact same network
architecture---8 layers, 27 million connections and 250K
parameters---and can be trained to drive itself, in real-time, using a
web camera and a modest Raspberry Pi 3 quad-core platform.
Using DeepPicar, we analyze the Pi 3's computing capabilities to 
support end-to-end deep learning based real-time control of autonomous
vehicles. We also systematically compare other contemporary embedded
computing platforms using the DeepPicar's CNN based real-time control
software as a workload. 
We find all tested platforms, including the Pi 3, are capable of
supporting deep-learning based real-time control, from 20 Hz up to 100
Hz depending on hardware platform. 
However, shared resource contention remains an
important issue that must be considered in applying deep-learning
models on shared memory based embedded computing platforms.
\end{abstract}

%-------------------------------------------------------------------------
\input{intro}
\input{background}
\input{overview}
\input{evaluation}
\input{comparison}
\input{related}
\input{conclusion}
%-------------------------------------------------------------------------
%\bibliographystyle{abbrv}
\bibliography{reference}

\appendix
\input{appendix}
\end{document}
