\section{Introduction} \label{sec:intro}

% broad context:
% - advance in ai sparked interests in the robotics application, such as
%   self-driving cars.
% - in particular, deep neural network models are increasingly used
%   for perception and control of a vehicle. say. AI workloads.
%
%
Autonomous cars have been a topic of increasing interest in recent
years as many companies are actively developing related hardware
and software technologies toward fully autonomous driving capability without
any human intervention. Deep neural networks (DNNs) have been
sucessfully applied in various perception and control tasks in 
recent years, and they are important workloads for autonomous vehicles
as well. For example, Tesla Model S was known to use a specialized
chip (MobileEye EyeQ), which uses a deep neural network for vision-based
real-time obstacle detection and avoidance. More recently, researchers
are investigating DNN based end-to-end control of
cars~\cite{Bojarski2016} and other robots. It is expected that more
DNN based Artifical Intelligence workloads may be used in future
autonomous vehicles.

% big problem
Executing these AI workloads on a embedded computing platform that can
be used in a car poses several additional challenges. First, many AI
workloads in vehicles are computationaly demanding and have strict
real-time requirements. For example, latency in a vision-based object
detection task may directly linked to safety of the vehicle. This
requires a high computing capacity as well as means to guaranteeing
the timings. On the other hand, the computing hardware platform must
also satisfy cost, size, weight, and power constraints, which require
highly efficient computing platform. These two conflicting
requirements  complicate the platform selection process as observed in
~\cite{Otterness2017}, which evaluated vision workloads on
NVIDIA's Tegra TX1 platform.
%% For example, while today's self-driving car
%% prototype equip more \$100,000 
%% of computers and sensors~\cite{juliussen2014emerging}, a study
%% found that aveage consumers are willing to pay much less amount of
%% extra cost for a self-driving capability~\cite{Daziano2017}.
%% https://qz.com/924212/what-it-really-costs-to-turn-a-car-into-a-self-driving-vehicle/ 

% related work and remaing problems
To understand what kind of computing hardware is needed for AI
workloads, we need a testbed and realistic workloads. While a real car
testbed would be most ideal, it is not only highly expensive but also
poses serious safety concerns that hinder development and exploration.
Therefore, there is a strong need for safer and less costly testbeds
that still employ state-of-the-art AI technologies. There are already
several relatively inexpensive RC-car based testbeds, such as MIT
RaceCar~\cite{shin2017project} and UPenn's F1$/$10 racecar~\cite{upennf1tenth}.
However, these RC-car testbeds still cost more than \$3,000.

% our goals
Instead, we want to build a low cost testbed that still employs the
state-of-the art AI technologies. Specifically, we focus on a deep
convolutional neural network (CNN) based end-to-end control system,
which was developed for a real self-driving car, NVIDIA
DAVE-2~\cite{Bojarski2016}, and use the same moethodology on a
smaller, safer and less costly setup. In developing the testbed, our
goals are (1) analyze real-time issues in DNN based end-to-end
control; (2) evalute real-time performance of contemporarly embedded
multicore platforms for the AI workloads.

% DeepPicar introduction
In this paper, we present DeepPicar, a low-cost autonomous car
platform for research and education. From hardware perspective, 
DeepPicar is comprised of a Raspberry Pi 3 Model B quad-core
computer, a web camera and a RC car, all of which are affordable
components (less than \$200 in total).
The DeepPicar, however, employs state-of-the-art AI
techonologies, including a vision-based end-to-end control system that
utilizes a deep convolutional nueral network (CNN).
The network receives an image frame from a single forward
looking camera as input and generates a predicted steering angle
value as output at each control period in \emph{real-time}. 
The network has 9 layers, about 27 million connections
and 250 thousand parameters (weights).
The network architecture is identifical to that of NVIDIA's DAVE-2
self-driving car~\cite{Bojarski2016}, which uses much more powerful
computer (NVIDIA's automotive specialized DRIV-PX
computer~\cite{drivepx}) than the Raspberry Pi~3.
We chose to use the Pi 3 not only because of its
affordability but also because it is representative
of today's mainstream low-end multicore platforms, found in
smartphones and other embedded devices.

%% Other than the difference in scale (RC car vs. real car), the only other
%% differences between the two systems---from the computing
%% perspective---are that our system is implemented in
%% TensorFlow~\cite{abadi2016tensorflow} and runs on a Raspberry Pi 3
%% whereas NVIDIA's DAVE-2 systems is implemented in Torch
%% 7~\cite{collobert2011torch7} and runs on a Drive PX computer (NVIDIA's
%% automotive specialized computing system~\cite{drivepx}), which is more
%% powerful but also more expensive.

% how we trained (maybe moved to a later section)
We follow the standard supervised learning methodology to train the
system to follow tracks on the ground. We collect data for
taining and validation by manually  
controlling the RC car and recording the vision (from the webcam
mounted on the RC-car) and the human control inputs. We then train the
network offline using the collected data on a desktop computer, which
equips a NVIDIA GTX 1060 GPU. Finally, the trained network is copied
back to the Raspberry Pi, which is then used to perform interference
operations---locally on the Pi---in the car's main control loop in
real-time. For real-time control, each inference operation must
be completed within the desired control period. (e.g., 50ms period for
20Hz control frequency.)
% how we evaluated (in terms real-time performance)

% what are our findings?
\fixme{TBD: Summary of our findings}

% contributions
The {\bf contributions} of this paper are as follows:
\begin{itemize}
  \item We present the design and implementation of a
    low-cost autonomous vehicle testbed DeepPicar, which utilizes the
    state-of-the-art aritificial intelligence techniques.
  \item We provide an analysis and case-study of real-time issues in the
    DeepPicar.
  \item We systematically compare real-time computing capabilities of
    multiple embedded computing platforms in the contex of a
    vision-based autnomous driving.
\end{itemize}

%% The DeepPicar is comprised of a Raspberry
%% Pi 3 Model B, a camera and a low cost RC car.

%% By creating and using the Picar platform, we seek to accomplish the 
%% following three goals. First, the significant reduction of the overall
%% cost required 
%% would make autonomous driving research more accessible to interested
%% individuals/parties. Furthermore, it would remove the concerns of
%% creating replacement platforms as each part, or the entire system,
%% could be replaced relatively inexpensively. Second, the utilization of
%% a more cost-efficient platform would allow for a better understanding
%% of the performance requirements necessary for efficiently operating
%% autonomous vehicles. Finally, we strive to achieve the ability to
%% compare the real-time performance of multiple embedded computing
%% platforms. 

%% We display the efficacy of the Picar by training and testing the
%% DeepTesla DNN \cite{} in a custom-made environment. We find that the
%% Picar is capable of consistently accomplishing all real-time
%% operations required for autonomous driving in a 50 millisecond frame. 

The remaining sections of the paper are as follows: Section II gives
an overview of the platform, including the high-level system and the
methods used for training and inference. Section III discusses the
ways/methodologies in which training data was collected. Section IV
outlines the network architecture. This is followed by the real-time
DNN inferencing in Section V. Section VI reviews the online/offline
training done with the platform, with an evaluation given in Section
VII. Section VIII gives a discussion of related works, and the paper
finishes with conclusions in Section IX. 


%% it is necessary that all real-time operations are successfully
%% performed prior to their deadlines. This requires that the AV platform
%% be capable of completing all necessary computations in a timely
%% manner, while maintaining a high level of accuracy. Consequently, the
%% cost of creating a platform capable of self-driving can be relatively
%% high, especially in the current cost-sensitive climate of the
%% automotive industry \cite{}. The overall price for an autonomous
%% vehicle platform currently acts as a bottleneck, especially from an
%% academic standpoint, where cost is an important factor. For many
%% researchers and students, the charge associated with autonomous
%% vehicle research is a significant barrier. These same parties may also
%% be deterred from participating in autonomous vehicle research due to
%% the potential for their developed platforms to break in the
%% experimental process. The idea of building one relatively expensive
%% platform may not be too daunting for some, but the notion of
%% potentially making multiple identical platforms in case of accidents
%% may be overwhelming.
%% Toward this end, we explore the possibility of
%% developing a low-cost system that still employs state-of-the-art AI
%% technologies and is capable of executing real-time autonomous vehicle
%% operations. 

